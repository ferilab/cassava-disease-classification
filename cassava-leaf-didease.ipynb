{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a deep learning approach to classify images taken from cassava leaves in 5 categories: one of 4 types of diseases or the healhy group.\n",
    "\n",
    "The data set is available in kaggle.com and includes 21397 images of cassava corps taken by farmers or other individuals that are labeled by experts. Further details on the dataset and the issue are availabl on kaggle.com.\n",
    "\n",
    "*** Important: the code is tailored to be run on colab. To run it on the computer, the data needs to be downloaded on the system and necessary training and test subdirectories be made and refered to on the local system.\n",
    "The codes for that are commented out in this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First import the necessary libraries and modules\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import shutil\n",
    "from shutil import copyfile\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000015157.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000201771.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100042118.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000723321.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000812911.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21392</th>\n",
       "      <td>999068805.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21393</th>\n",
       "      <td>999329392.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21394</th>\n",
       "      <td>999474432.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21395</th>\n",
       "      <td>999616605.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21396</th>\n",
       "      <td>999998473.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21397 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             image_id  label\n",
       "0      1000015157.jpg      0\n",
       "1      1000201771.jpg      3\n",
       "2       100042118.jpg      1\n",
       "3      1000723321.jpg      1\n",
       "4      1000812911.jpg      3\n",
       "...               ...    ...\n",
       "21392   999068805.jpg      3\n",
       "21393   999329392.jpg      3\n",
       "21394   999474432.jpg      1\n",
       "21395   999616605.jpg      4\n",
       "21396   999998473.jpg      4\n",
       "\n",
       "[21397 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The next few code cells are to download the dataset fro kaggle onto colab.\n",
    "\n",
    "# 1 - Uninstall and reinstall kaggle\n",
    "!pip uninstall -y kaggle\n",
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2- To use the Kaggle API we need to set environment variables\n",
    "\n",
    "# Sign up in kaggle if you do not already have an account;\n",
    "# sign in to Kaggle;\n",
    "# click on account;\n",
    "# click the 'Create New API Token' button;\n",
    "# a .json file will be downloaded on your system;\n",
    "# open the file using any text editor;\n",
    "# you'll find your username and password there, copy and paste them in the two follwing codes and run it.\n",
    "\n",
    "os.environ[\"KAGGLE_USERNAME\"] = 'PUT YOUR USERNAME HERE'\n",
    "os.environ[\"KAGGLE_KEY\"] = 'PUT YOUR PASSWORD HERE'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3- Now download the data from the kaggle\n",
    "\n",
    "raw_data_dir = \"input/raw\"\n",
    "\n",
    "!kaggle competitions download -c cassava-leaf-disease-classification -p {raw_data_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4- Just to check out that the zip file is downloaded in the colab\n",
    "!ls {raw_data_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Well, the mission almost accomplished and we got the dataset in our colab. Now,\n",
    "# to unzip the zipped downloaded file we'll use Fuze-zip. First we need to install it. \n",
    "\n",
    "!apt-get install -y fuse-zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, we need to extract the data from the zipped file using fuze-zip\n",
    "\n",
    "input_dir = \"/tmp/kaggle-data\"\n",
    "!mkdir {input_dir}\n",
    "!fuse-zip input/raw/cassava-leaf-disease-classification.zip {input_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see everything looks normal and the dubdirectories are in place\n",
    "!ls {input_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The unzipped dataset, as is available on kaggle, is now in the temp subdirectory of colab.\n",
    "# It will remain there for 90 min if we do nothing hereinafter, and for 12 hours if we use it.\n",
    "# Let's set a variable for the base path of our data.\n",
    "\n",
    "base_path = '/tmp/kaggle-data/'\n",
    "\n",
    "os.listdir(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  It's always a good idea to breifly examine the data to see if all labels are valied or see ...\n",
    "#  We'll see that all images are labeled with their file names and numbers as classes. Class 4 represents healthy leaves.\n",
    "\n",
    "# Note: My examination showed that there are some mislabeled images, like apparantly infected leaves that are \n",
    "# labeled healthy (class 4), or instances of wrongly labled sick leaves, though I am not a corp or agriculture expert.\n",
    "\n",
    "image_labels= pd.read_csv(base_path + 'train.csv')\n",
    "image_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This line is only needed on my computer not on the colab\n",
    "\n",
    "# path = '/Users/apple/Documents/Fereidoun/Projects/kaggle/cassava-leaf-disease-classification/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We divide the classes on the training and test sets in seperate subfolders to use flowfromdirectory method\n",
    "\n",
    "os.mkdir(base_path + 'subset-train') \n",
    "os.mkdir(base_path + 'subset-test') \n",
    "\n",
    "for label in range(5):\n",
    "    os.mkdir(base_path + 'subset-train/label-' + str(label)) # We'll put images of each label in on of these subfolders \n",
    "    os.mkdir(base_path + 'subset-test/label-' + str(label)) # We'll put images of each label in on of these subfolders \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After shuffeling the list of images, we devide the data to training and test sets by putting them in seperate subfolders.\n",
    "# First we make the subdirectory for the training set.\n",
    "\n",
    "subgroup = image_labels_shuffled[:training_size] # pick images for training\n",
    "files = subgroup.image_id\n",
    "for f in files:\n",
    "    shutil.copy(base_path + 'train_images/' + f, base_path + 'subset-train/')\n",
    "\n",
    "# rearrange training images using their labels in seperate labeled (named) subdirectories\n",
    "for label in range(5):\n",
    "    mask = subgroup['label'] == label \n",
    "    category = subgroup.loc[mask]\n",
    "    files = category.image_id\n",
    "    dest_folder = base_path + 'subset-train/label-' + str(label) +'/'\n",
    "    for f in files:\n",
    "        file_path = base_path + 'subset-train/' + f\n",
    "        if os.path.getsize(file_path) > 0:\n",
    "            shutil.move(file_path, dest_folder)\n",
    "        else:\n",
    "            print(filename + \" is zero length, so ignoring.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, we put the rest of images in another subdirectory as the test\n",
    "\n",
    "subgroup = image_labels_shuffled[training_size:] # pick the rest of images for testing\n",
    "files = subgroup.image_id\n",
    "for f in files:\n",
    "    shutil.copy(base_path + 'train_images/' + f, base_path + 'subset-test/')\n",
    "\n",
    "# rearrange test images using their labels in seperate labeled (named) subdirectories\n",
    "for label in range(5):\n",
    "    mask = subgroup['label'] == label \n",
    "    category = subgroup.loc[mask]\n",
    "    files = category.image_id\n",
    "    dest_folder = base_path + 'subset-test/label-' + str(label) +'/'\n",
    "    for f in files:\n",
    "        file_path = base_path + 'subset-test/' + f\n",
    "        if os.path.getsize(file_path) > 0:\n",
    "            shutil.move(file_path, dest_folder)\n",
    "        else:\n",
    "            print(filename + \" is zero length, so ignoring.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  To check the number of images of different classes (labels) in the training and test sets\n",
    "\n",
    "print('No. of images of different labels in the training set.\\n')\n",
    "for i in range(5):\n",
    "  print(f'Label_{i}: ', len(os.listdir(base_path + 'subset-train/label-' + str(i))))\n",
    "\n",
    "print('\\nNo. of images of different labels in the test set.\\n')\n",
    "for i in range(5):  \n",
    "  print(f'Label{i}: ', len(os.listdir(base_path + 'subset-test/label-' + str(i))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep neural network is going to be the backbone of our algorithm. We'll use Keras and Tensorflow to this end.\n",
    "# Convolving, pooling, and dropping out a small ratio of adjacent trained nerons are all the supplimentary tecniques\n",
    "# employed to boost the performance of the method.\n",
    "\n",
    "# First designe the model.\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The next line is a trick to improve the test accuracy even more by removing\n",
    "    # one of every two neighboring neurons right after being traied. 0.5 is too aggressive though.\n",
    "    tf.keras.layers.Dropout(0.2),   \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "# And then, set up the parameters of the model.\n",
    "\n",
    "model.compile(optimizer=RMSprop(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 5 classes.\n",
      "Found 1000 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# Now, we also add augmentation to the algorithm to make up for the position and angle of the regions of interests\n",
    "# (infected areas on leaves) in the images. We also rescale all the images to 0-1 range (from 0-255 range).\n",
    "\n",
    "size_of_batch = 50                                        # we will set 'bath size' in the training stage according to this\n",
    "epoch_steps = math.ceil(training_size/size_of_batch)           # the steps per batch can be calculated based on the batch size\n",
    "val_steps = math.ceil(test_size/size_of_batch)\n",
    "\n",
    "train_dir = os.path.join(base_path, 'subset-train/')\n",
    "validation_dir = os.path.join(base_path, 'subset-test/')\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255,\n",
    "                                  #  rotation_range = 40,\n",
    "                                   width_shift_range = 0.3,\n",
    "                                   height_shift_range = 0.3,\n",
    "                                   shear_range = 0.3,\n",
    "                                   zoom_range = 0.7,\n",
    "                                  #  horizontal_flip = True,\n",
    "                                   fill_mode = 'nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size=size_of_batch,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    target_size=(150, 150))\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "validation_generator = validation_datagen.flow_from_directory(validation_dir,\n",
    "                                                              batch_size=size_of_batch,\n",
    "                                                              class_mode='categorical',\n",
    "                                                              target_size=(150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 - 2745s - loss: 2.2863 - accuracy: 0.5390 - val_loss: 1.3107 - val_accuracy: 0.6050\n",
      "Epoch 2/10\n",
      "100/100 - 863s - loss: 1.1326 - accuracy: 0.6200 - val_loss: 1.1291 - val_accuracy: 0.6090\n",
      "Epoch 3/10\n"
     ]
    }
   ],
   "source": [
    "# We save the performance indicators of every epoch in a variable.\n",
    "# Note: every epoch with the current configuration and setting will take about 570 seconds.\n",
    "\n",
    "history = model.fit(train_generator, \n",
    "                    epochs = 20,  \n",
    "                    steps_per_epoch = epoch_steps,\n",
    "                    validation_data = validation_generator, \n",
    "                    validation_steps = val_steps,\n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here the progress of model's performance indicators versus the epoch number can be evaluated.\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image  as mpimg\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "# Retrieve a list of indicators on training and test data\n",
    "# sets for each epoch\n",
    "#-----------------------------------------------------------\n",
    "acc=history.history['accuracy']\n",
    "val_acc=history.history['val_accuracy']\n",
    "loss=history.history['loss']\n",
    "val_loss=history.history['val_loss']\n",
    "\n",
    "epochs=range(1, len(acc)+1) # Get number of epochs\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation accuracies versus epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, acc, 'bo', \"Training Accuracy\")\n",
    "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
    "plt.title('Training and validation accuracies')\n",
    "plt.xlabel('Epoch number')\n",
    "plt.ylim\n",
    "plt.figure()\n",
    "\n",
    "#------------------------------------------------\n",
    "# Plot training and validation loss per epoch\n",
    "#------------------------------------------------\n",
    "plt.plot(epochs, loss, 'bo', \"Training Loss\")\n",
    "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epoch number')\n",
    "plt.legend()\n",
    "\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** Use this code only if for any reason you needed to remove a directory made as above from the \n",
    "# downloaded zip file from kaggle\n",
    "\n",
    "# shutil.rmtree(base_path + 'subset-test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
